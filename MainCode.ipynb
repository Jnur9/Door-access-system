{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b3cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from pyzbar.pyzbar import decode   #pyzbar helps in detection and decoding of the qrcode\n",
    "import pickle,time\n",
    "import pyttsx3   #offline lib for tts\n",
    "import serial  #for serial communication with arduino\n",
    "from secret_key import key,registered_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9490fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish connection with arduino\n",
    "arduino = serial.Serial(port='COM3', baudrate=9600)\n",
    "\n",
    "#Specify the recognizer\n",
    "face_cascade=cv2.CascadeClassifier('C:\\\\Users\\\\HP\\\\anaconda3\\\\envs\\\\machinevision\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt2.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainedModel.yml')  # Reading the stored trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d9bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8gjh59jfhuhf847746273239u283ry4fbg4474728ydhd0b5b162e0b0b1789778\n",
      "8gjh59jfhuhf847746273239u283ry4fbg4474728ydhd0b5b162e0b0b1789778\n"
     ]
    }
   ],
   "source": [
    "engine = pyttsx3.init() \n",
    "\n",
    "#Loading the label-id relation to get the name of the labels.\n",
    "with open(\"label_ids.pickle\",'rb') as fr:    \n",
    "    og_labels=pickle.load(fr)\n",
    "\n",
    "#labels are of the form {name:id} we want to invert this form to {id:name}\n",
    "labels={k:v for v,k in og_labels.items()}\n",
    "\n",
    "\n",
    "def speak(text):  #fn to convert text to speech\n",
    "    engine.say(text)\n",
    "    engine.runAndWait() \n",
    "\n",
    "flag=True  # to switch between face recognition and qr code decoding\n",
    "\n",
    "MAX_TRY=2\n",
    "tries=0  #for invalid face recognition\n",
    "flag_face_recognised=False   #to keep track if the user face is recognized\n",
    "flag_face_not_recognised=False\n",
    "\n",
    "no_of_adjacent_prediction=0\n",
    "no_face_detected=0  #to track the number of times the face is detected\n",
    "prev_predicted_name=''   #to keep track of the previously predicted face(w.r.t frame)\n",
    "count_frames = total_no_face_detected = 0\n",
    "\n",
    "time_out_no_of_frames_after_qrcode=0\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "clr=(255,255,255)\n",
    "cap=cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    if(flag):\n",
    "        for i in decode(frame):\n",
    "            decoded_data=i.data.decode(\"utf-8\")   #converts bytes to string value\n",
    "            print(decoded_data)   \n",
    "\n",
    "            #Drawing polygon on frame (tilts w.r.t orientation)\n",
    "            pts=np.array([i.polygon],np.int32)\n",
    "\n",
    "            pts=pts.reshape((-1,1,2))  \n",
    "            cv2.polylines(frame,[pts],True,(0,0,255),2)\n",
    "            # print(pts)\n",
    "        \n",
    "            #Display text\n",
    "            rect_pts=i.rect #using rect point as origin for text as we don't want the text to tilt with the qrcode\n",
    "            fontScale=0.8\n",
    "            thickness=1\n",
    "            # cv2.putText(frame,decoded_data,(rect_pts[0],rect_pts[1]),cv2.FONT_HERSHEY_SIMPLEX,fontScale,(255,0,0),thickness)\n",
    "            # print(rect_pts)\n",
    "\n",
    "            \n",
    "            if(decoded_data.lower()==key):   #Check private key\n",
    "                flag=False\n",
    "                tries=0\n",
    "                speak(\"Valid qr code, proceed to face recognition\")\n",
    "                time_out_no_of_frames_after_qrcode=0\n",
    "                \n",
    "            else:\n",
    "                # print(\"INVALID QR CODE\")\n",
    "                speak(\"INVALID QR CODE\")\n",
    "              \n",
    "        cv2.imshow('Face Recognition Cam',frame)\n",
    "    else:\n",
    "        count_frames+=1\n",
    "        time_out_no_of_frames_after_qrcode+=1\n",
    "\n",
    "\n",
    "        # print(ret,frame)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces=face_cascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)\n",
    "\n",
    "        # print(\"FACES : \",faces)\n",
    "        # print(type(frame))   #The frames are automatically converted into numpy arrays of pixels.\n",
    "        for (x,y,w,h) in faces:\n",
    "\n",
    "            total_no_face_detected+=1\n",
    "            no_face_detected+=1\n",
    "\n",
    "            # print(x,y,w,h)\n",
    "            roi_gray=gray[y:y+h,x:x+w]  #roi(region of interest)\n",
    "            # roi_color=frame[y:y+h,x:x+w]\n",
    "\n",
    "            id,confidence=recognizer.predict(roi_gray)\n",
    "            # print(id,confidence,labels[id])\n",
    "            if(confidence<=70  and (labels[id] in registered_users)):\n",
    "                print(\"PREDICTED : \",labels[id])\n",
    "                \n",
    "                name=labels[id] \n",
    "                cv2.putText(frame,name.replace('_',' ').title(),(x,y-5),font,0.8,clr,1,cv2.LINE_AA)\n",
    "\n",
    "                if(prev_predicted_name==name):\n",
    "                    no_of_adjacent_prediction+=1\n",
    "                else:\n",
    "                    no_of_adjacent_prediction=0\n",
    "\n",
    "                prev_predicted_name=name        \n",
    "\n",
    "\n",
    "\n",
    "            # color=(255,0,0) #BGR 0-255\n",
    "            thickness=1\n",
    "            end_coord_x=x+w\n",
    "            end_coord_y=y+h\n",
    "\n",
    "\n",
    "            if(no_of_adjacent_prediction>15):   #no_of_adjacent_prediction is only updated when the confidence of classification is >80\n",
    "                cv2.putText(frame,\"Welcome home \"+name.replace('_',' ').title(),(160,460),font,0.8,clr,thickness,cv2.LINE_AA)  #to print on frame\n",
    "                flag_face_recognised=True\n",
    "                no_of_adjacent_prediction=0\n",
    "                no_face_detected=0\n",
    "\n",
    "            elif(no_face_detected>=30):   #a face is detected 30 times but not yet recognised or classified, then show user not recognised \n",
    "                cv2.putText(frame,\"Face Not Recognised\",(160,460),font,0.8,clr,thickness,cv2.LINE_AA)\n",
    "                flag_face_not_recognised=True\n",
    "                no_of_adjacent_prediction=0\n",
    "                no_face_detected=0\n",
    "\n",
    "            cv2.rectangle(frame,(x,y),(end_coord_x,end_coord_y),(0,0,0),2)  #Drawing the rectangle on the frame\n",
    "\n",
    "        cv2.imshow('Face Recognition Cam',frame)\n",
    "\n",
    "        if(flag_face_recognised):    #if face is recognized then open the door\n",
    "            speak(\"Welcome \"+name.replace('_',' ')+\", unlocking door. The door will remain open for the next 5 seconds\")\n",
    "            arduino.write(bytes('o', 'utf-8'))  #Output the given byte string over the serial port.\n",
    "            print(\"DOOR is OPEN\")\n",
    "\n",
    "            \n",
    "            time.sleep(5)\n",
    "            speak(\"Closing door\")\n",
    "            arduino.write(bytes('c', 'utf-8'))  #Output the given byte string over the serial port.\n",
    "            print(\"DOOR is CLOSED\")\n",
    "            flag_face_recognised=False\n",
    "            flag=True         #to start from qrcode\n",
    "\n",
    "        if(flag_face_not_recognised):\n",
    "            speak(\"Face not recognised. The door will remain closed\")    \n",
    "            time.sleep(2)\n",
    "            flag_face_not_recognised=False\n",
    "            tries+=1\n",
    "            if(tries>=MAX_TRY):\n",
    "                speak(\"User authentication failed as face is not recognised\")\n",
    "                flag=True       #to start from qrcode\n",
    "                tries=0\n",
    "\n",
    "        if(time_out_no_of_frames_after_qrcode>=400):\n",
    "            speak(\"User authentication failed due to time out\")\n",
    "            flag=True     #to start from qrcode\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # cv2.imshow('TRIAL',frame)\n",
    "\n",
    "    ch=cv2.waitKey(20) #delay of 1ms    \n",
    "    if(ch==113):\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"No. of frames : \",count_frames,\" |   No. of times face detected : \",total_no_face_detected)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf1592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
